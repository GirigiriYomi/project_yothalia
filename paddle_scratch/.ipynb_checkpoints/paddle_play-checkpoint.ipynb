{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e7408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91591\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\n",
      "  warnings.warn(\"paddleaudio C++ extension is not available.\")\n"
     ]
    }
   ],
   "source": [
    "from paddlespeech.server.engine.asr.python.asr_engine import ASREngine, PaddleASRConnectionHandler\n",
    "\n",
    "from paddlespeech.cli.asr.infer import ASRExecutor\n",
    "import pyaudio, wave\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35ad20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "class mic_thread(threading.Thread):\n",
    "    threads = []\n",
    "    id = 0\n",
    "    thread_lock = threading.Lock()\n",
    "    mic_queue = queue.Queue(10)\n",
    "    \n",
    "    def __init__(self, name, source):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.source = source\n",
    "        self.stop = False\n",
    "        \n",
    "        self.id = mic_thread.id\n",
    "        mic_thread.id = mic_thread.id+1\n",
    "        \n",
    "        mic_thread.threads.append(self)\n",
    "        \n",
    "    def run(self):\n",
    "        with mic as source:\n",
    "            # r.energy_threshold = 8000 # This filters noise\n",
    "            r.dynamic_energy_threshold = False\n",
    "            r.adjust_for_ambient_noise(source,2)\n",
    "            \n",
    "            r.pause_threshold = 1.5\n",
    "            print(\"Start talk..\")\n",
    "            while not self.stop:\n",
    "                print(\"Listening..\")\n",
    "                try:\n",
    "                    audio = r.listen(source,timeout=10) # no talk within 2 sec, re-loop\n",
    "                except sr.exceptions.WaitTimeoutError:\n",
    "                    continue\n",
    "                        \n",
    "                print(\"Done lisening\")\n",
    "                wav_data = audio.get_wav_data(convert_rate = 16000)\n",
    "                \n",
    "                mic_thread.thread_lock.acquire()\n",
    "                mic_thread.mic_queue.put(io.BytesIO(wav_data))\n",
    "                mic_thread.thread_lock.release()\n",
    "                \n",
    "    def terminate(self):\n",
    "        self.stop = True\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12693ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class crASR:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 创建对象参数\n",
    "        class _conf:\n",
    "            def __init__(self, **kwargs):\n",
    "                for key in kwargs:\n",
    "                    setattr(self, key, kwargs[key])\n",
    "        # 初始化ASR\n",
    "        self.asr = ASREngine()\n",
    "        # 以指定参数方式生成对象并初始化ASR\n",
    "        self.asr.init(_conf(\n",
    "            model='conformer_wenetspeech',\n",
    "            lang='zh', # zh_en en zh\n",
    "            sample_rate=16000,\n",
    "            cfg_path=None,  # 自定义配置文件路径(可选)\n",
    "            ckpt_path=None,  # 自定义模型文件路径(可选)\n",
    "            decode_method='attention_rescoring',\n",
    "            force_yes=True,\n",
    "            device=None))\n",
    "        self.asr_handle = PaddleASRConnectionHandler(self.asr)\n",
    "\n",
    "    def predict(self, wavData):\n",
    "        \"\"\"\n",
    "        ASR预测\n",
    "        :param wavData: 需要预测的音频，会根据传入类型自动识别：路径(str 相对|绝对)、音频流、内存BytesIO对象\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if type(wavData) == str:\n",
    "            wavData = filesystem_get_contents(wavData, 'rb')\n",
    "        elif type(wavData) == io.BytesIO:\n",
    "            wavData = wavData.getvalue()\n",
    "\n",
    "        start = time.time()\n",
    "        self.asr_handle.run(wavData)\n",
    "        text = self.asr_handle.output\n",
    "        print(\"ASR预测消耗时间：%dms, 识别结果: %s\" % (round((time.time() - start) * 1000), text))\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a725de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Microphone (WEB CAM)',\n",
       " 'Headset Microphone (Oculus Virt',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " '扬声器 (Realtek High Definition Au',\n",
       " 'Realtek Digital Output (Realtek',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition ',\n",
       " '鑰虫満 (Oculus Virtual Audio Device',\n",
       " '主声音捕获驱动程序',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Microphone (WEB CAM)',\n",
       " 'Headset Microphone (Oculus Virtual Audio Device)',\n",
       " '主声音驱动程序',\n",
       " '扬声器 (Realtek High Definition Audio)',\n",
       " 'Realtek Digital Output (Realtek High Definition Audio)',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (Oculus Virtual Audio Device)',\n",
       " 'Realtek Digital Output (Realtek High Definition Audio)',\n",
       " '扬声器 (Realtek High Definition Audio)',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (Oculus Virtual Audio Device)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Microphone (WEB CAM)',\n",
       " 'Headset Microphone (Oculus Virtual Audio Device)',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " '鑰虫満 ()',\n",
       " 'Output 1 (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Output 2 (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Input (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Headset Microphone (OCULUSVAD Wave Microphone Headphone)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " '麦克风 (Realtek HD Audio Mic input)',\n",
       " 'SPDIF Out (Realtek HDA SPDIF Out)',\n",
       " '立体声混音 (Realtek HD Audio Stereo input)',\n",
       " '绾胯矾杈撳叆 (Realtek HD Audio Line input)',\n",
       " '麦克风 ()',\n",
       " 'Speakers ()',\n",
       " 'Output (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))',\n",
       " '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))',\n",
       " '麦克风 (WEB CAM)',\n",
       " '麦克风 (JOUNIVO JV601)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebd1b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Can't find \"d-zh-16k\" in resource. Model name must be one of ['conformer_wenetspeech-zh-16k', 'conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_aishell-zh-16k', 'conformer_online_aishell-zh-16k', 'transformer_librispeech-en-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2offline_aishell-zh-16k', 'deepspeech2online_aishell-zh-16k', 'deepspeech2offline_librispeech-en-16k', 'conformer_talcs-codeswitch_zh_en-16k']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m asr \u001b[38;5;241m=\u001b[39m \u001b[43mcrASR\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m      3\u001b[0m mic \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mMicrophone(device_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mcrASR.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masr \u001b[38;5;241m=\u001b[39m ASREngine()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 以指定参数方式生成对象并初始化ASR\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_conf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# zh_en en zh\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 自定义配置文件路径(可选)\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 自定义模型文件路径(可选)\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_rescoring\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_yes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masr_handle \u001b[38;5;241m=\u001b[39m PaddleASRConnectionHandler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\server\\engine\\asr\\python\\asr_engine.py:75\u001b[0m, in \u001b[0;36mASREngine.init\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh_en\u001b[39m\u001b[38;5;124m\"\u001b[39m :\n\u001b[0;32m     73\u001b[0m     cs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodeswitch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcs\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialize ASR server engine successfully on device: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     85\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\cli\\asr\\infer.py:159\u001b[0m, in \u001b[0;36mASRExecutor._init_from_path\u001b[1;34m(self, model_type, lang, codeswitch, sample_rate, cfg_path, decode_method, num_decoding_left_chunks, ckpt_path)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     tag \u001b[38;5;241m=\u001b[39m model_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m lang \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m sample_rate_str\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_task_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_resource\u001b[38;5;241m.\u001b[39mres_dir\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_resource\u001b[38;5;241m.\u001b[39mres_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfg_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\resource\\resource.py:74\u001b[0m, in \u001b[0;36mCommonTaskResource.set_task_model\u001b[1;34m(self, model_tag, model_type, skip_download, version)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_task_model\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     63\u001b[0m                    model_tag: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     64\u001b[0m                    model_type: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     65\u001b[0m                    skip_download: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     66\u001b[0m                    version: Optional[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set model tag and version of current task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        version (Optional[str], optional): Version of pretrained model. Defaults to None.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m model_tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_models, \\\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m in resource. Model name must be one of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_tag, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_models\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_default_version(model_tag)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Can't find \"d-zh-16k\" in resource. Model name must be one of ['conformer_wenetspeech-zh-16k', 'conformer_online_wenetspeech-zh-16k', 'conformer_u2pp_online_wenetspeech-zh-16k', 'conformer_online_multicn-zh-16k', 'conformer_aishell-zh-16k', 'conformer_online_aishell-zh-16k', 'transformer_librispeech-en-16k', 'deepspeech2online_wenetspeech-zh-16k', 'deepspeech2offline_aishell-zh-16k', 'deepspeech2online_aishell-zh-16k', 'deepspeech2offline_librispeech-en-16k', 'conformer_talcs-codeswitch_zh_en-16k']"
     ]
    }
   ],
   "source": [
    "asr = crASR()\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone(device_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e677c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone = mic_thread(\"local mic\",mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8bcd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talk..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "\u001b[32m2023-10-18 21:06:00.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpaddlespeech.s2t.modules.ctc\u001b[0m:\u001b[36m_init_ext_scorer\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mbegin to initialize the external scorer for decoding\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-18 21:06:00,126] [    INFO] - name 'Scorer' is not defined\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\server\\engine\\asr\\python\\asr_engine.py:120\u001b[0m, in \u001b[0;36mPaddleASRConnectionHandler.run\u001b[1;34m(self, audio_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masr_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m infer_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py:347\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>._decorate_function\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\cli\\asr\\infer.py:300\u001b[0m, in \u001b[0;36mASRExecutor.infer\u001b[1;34m(self, model_type)\u001b[0m\n\u001b[0;32m    299\u001b[0m decode_batch_size \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoding_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff_top_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc_bsearch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m result_transcripts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecode(audio, audio_len)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\s2t\\modules\\ctc.py:285\u001b[0m, in \u001b[0;36mCTCDecoder.init_decoder\u001b[1;34m(self, batch_size, vocab_list, decoding_method, lang_model_path, beam_alpha, beam_beta, beam_size, cutoff_prob, cutoff_top_n, num_processes)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoding_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctc_beam_search\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_ext_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvocab_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search_decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\s2t\\modules\\ctc.py:192\u001b[0m, in \u001b[0;36mCTCDecoder._init_ext_scorer\u001b[1;34m(self, beam_alpha, beam_beta, language_model_path, vocab_list)\u001b[0m\n\u001b[0;32m    190\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin to initialize the external scorer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor decoding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ext_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mScorer\u001b[49m(beam_alpha, beam_beta,\n\u001b[0;32m    193\u001b[0m                           language_model_path, vocab_list)\n\u001b[0;32m    194\u001b[0m lm_char_based \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ext_scorer\u001b[38;5;241m.\u001b[39mis_character_based()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Scorer' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m mic_thread\u001b[38;5;241m.\u001b[39mthread_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 15\u001b[0m replyTxt \u001b[38;5;241m=\u001b[39m \u001b[43masr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# send to LLM afterward\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 音纹识别\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m, in \u001b[0;36mcrASR.predict\u001b[1;34m(self, wavData)\u001b[0m\n\u001b[0;32m     34\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masr_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masr_handle\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\server\\engine\\asr\\python\\asr_engine.py:131\u001b[0m, in \u001b[0;36mPaddleASRConnectionHandler.run\u001b[1;34m(self, audio_data)\u001b[0m\n\u001b[0;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(e)\n\u001b[1;32m--> 131\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: -1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "microphone.start()\n",
    "\n",
    "flag = True\n",
    "while flag:\n",
    "    if mic_thread.mic_queue.empty():\n",
    "        time.sleep(0.1)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    mic_thread.thread_lock.acquire()\n",
    "    msg = mic_thread.mic_queue.get(0)\n",
    "    mic_thread.thread_lock.release()\n",
    "\n",
    "        \n",
    "    replyTxt = asr.predict(msg)\n",
    "        \n",
    "    # send to LLM afterward\n",
    "    # 音纹识别\n",
    "        \n",
    "        \n",
    "    print(replyTxt)\n",
    "        \n",
    "    if (replyTxt == \"停下\"):\n",
    "        flag = False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43337f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe20a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59dfec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_thread.mic_queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "978ae110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<mic_thread(local mic, stopped 7024)>, <mic_thread(local mic, stopped 12264)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_thread.threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe742e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04000e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd154507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516a960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889a42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e1905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talk..\n"
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source) # This filters noise\n",
    "    r.pause_threshold = 1\n",
    "    print(\"Start talk..\")\n",
    "    while True:\n",
    "        print(\"Listening..\")\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8356495",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data = audio.get_wav_data(convert_rate = 16000)\n",
    "io_wav = io.BytesIO(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ec033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3cde665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virt', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Au', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition ', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': '主声音捕获驱动程序', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 13, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 14, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virtual Audio Device)', 'hostApi': 1, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 15, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 1, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 16, 'structVersion': 2, 'name': '主声音驱动程序', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 17, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 18, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 19, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 20, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 21, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 22, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 23, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 24, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.001, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 25, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 26, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 27, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.001, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 28, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virtual Audio Device)', 'hostApi': 2, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 29, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 30, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 2, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 16000.0}\n",
      "{'index': 31, 'structVersion': 2, 'name': '鑰虫満 ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n",
      "{'index': 32, 'structVersion': 2, 'name': 'Output 1 (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 33, 'structVersion': 2, 'name': 'Output 2 (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 34, 'structVersion': 2, 'name': 'Input (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 35, 'structVersion': 2, 'name': 'Headset Microphone (OCULUSVAD Wave Microphone Headphone)', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 36, 'structVersion': 2, 'name': 'Speakers (Realtek HD Audio output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 37, 'structVersion': 2, 'name': '麦克风 (Realtek HD Audio Mic input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 38, 'structVersion': 2, 'name': 'SPDIF Out (Realtek HDA SPDIF Out)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 39, 'structVersion': 2, 'name': '立体声混音 (Realtek HD Audio Stereo input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 40, 'structVersion': 2, 'name': '绾胯矾杈撳叆 (Realtek HD Audio Line input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 41, 'structVersion': 2, 'name': '麦克风 ()', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 42, 'structVersion': 2, 'name': 'Speakers ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 43, 'structVersion': 2, 'name': 'Output (NVIDIA High Definition Audio)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 44, 'structVersion': 2, 'name': '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 1, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n",
      "{'index': 45, 'structVersion': 2, 'name': '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n",
      "{'index': 46, 'structVersion': 2, 'name': '麦克风 (WEB CAM)', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 16000.0}\n",
      "{'index': 47, 'structVersion': 2, 'name': '麦克风 (JOUNIVO JV601)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# 查找虚拟麦克风的设备索引\n",
    "# 使用VB-Audio Virtual Cable\n",
    "\n",
    "mic_index = None\n",
    "for i in range(audio.get_device_count()):\n",
    "    print(audio.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa98fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b45ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e686475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9034b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"audio_file.wav\", \"wb\") as file:\n",
    "    file.write(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b87fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2adc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-30 10:39:44,235] [   ERROR] - Set device failed, please check if device is already used and the parameter 'device' in the yaml file\n",
      "[2023-09-30 10:39:44,236] [   ERROR] - 'dict' object has no attribute 'device'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr = ASREngine()\n",
    "asr.init({'model':'conformer_wenetspeech',\n",
    "            'lang':'zh',\n",
    "            'sample_rate':16000,\n",
    "            'cfg_path':None,  # 自定义配置文件路径(可选)\n",
    "            'ckpt_path':None,  # 自定义模型文件路径(可选)\n",
    "            'decode_method':'attention_rescoring',\n",
    "            'force_yes':True,\n",
    "            'device':'cuda'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
