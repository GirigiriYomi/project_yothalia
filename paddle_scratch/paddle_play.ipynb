{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e7408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91591\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddleaudio\\_extension.py:141: UserWarning: paddleaudio C++ extension is not available.\n",
      "  warnings.warn(\"paddleaudio C++ extension is not available.\")\n"
     ]
    }
   ],
   "source": [
    "from paddlespeech.server.engine.asr.python.asr_engine import ASREngine, PaddleASRConnectionHandler\n",
    "\n",
    "from paddlespeech.cli.asr.infer import ASRExecutor\n",
    "import pyaudio, wave\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35ad20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "class mic_thread(threading.Thread):\n",
    "    threads = []\n",
    "    id = 0\n",
    "    thread_lock = threading.Lock()\n",
    "    mic_queue = queue.Queue(10)\n",
    "    \n",
    "    def __init__(self, name, source):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.source = source\n",
    "        self.stop = False\n",
    "        \n",
    "        self.id = mic_thread.id\n",
    "        mic_thread.id = mic_thread.id+1\n",
    "        \n",
    "        mic_thread.threads.append(self)\n",
    "        \n",
    "    def run(self):\n",
    "        with mic as source:\n",
    "            # r.energy_threshold = 8000 # This filters noise\n",
    "            r.dynamic_energy_threshold = False\n",
    "            r.adjust_for_ambient_noise(source,2)\n",
    "            \n",
    "            r.pause_threshold = 1.5\n",
    "            print(\"Start talk..\")\n",
    "            while not self.stop:\n",
    "                print(\"Listening..\")\n",
    "                try:\n",
    "                    audio = r.listen(source,timeout=10) # no talk within 2 sec, re-loop\n",
    "                except sr.exceptions.WaitTimeoutError:\n",
    "                    continue\n",
    "                        \n",
    "                print(\"Done lisening\")\n",
    "                wav_data = audio.get_wav_data(convert_rate = 16000)\n",
    "                \n",
    "                mic_thread.thread_lock.acquire()\n",
    "                mic_thread.mic_queue.put(io.BytesIO(wav_data))\n",
    "                mic_thread.thread_lock.release()\n",
    "                \n",
    "    def terminate(self):\n",
    "        self.stop = True\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e12693ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class crASR:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 创建对象参数\n",
    "        class _conf:\n",
    "            def __init__(self, **kwargs):\n",
    "                for key in kwargs:\n",
    "                    setattr(self, key, kwargs[key])\n",
    "        # 初始化ASR\n",
    "        self.asr = ASREngine()\n",
    "        # 以指定参数方式生成对象并初始化ASR\n",
    "        self.asr.init(_conf(\n",
    "            model='deepspeech2online_wenetspeech',\n",
    "            lang='zh', # zh_en en zh\n",
    "            sample_rate=16000,\n",
    "            cfg_path=None,  # 自定义配置文件路径(可选)\n",
    "            ckpt_path=None,  # 自定义模型文件路径(可选)\n",
    "            decode_method='attention_rescoring',\n",
    "            force_yes=True,\n",
    "            device=None))\n",
    "        self.asr_handle = PaddleASRConnectionHandler(self.asr)\n",
    "\n",
    "    def predict(self, wavData):\n",
    "        \"\"\"\n",
    "        ASR预测\n",
    "        :param wavData: 需要预测的音频，会根据传入类型自动识别：路径(str 相对|绝对)、音频流、内存BytesIO对象\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if type(wavData) == str:\n",
    "            wavData = filesystem_get_contents(wavData, 'rb')\n",
    "        elif type(wavData) == io.BytesIO:\n",
    "            wavData = wavData.getvalue()\n",
    "\n",
    "        start = time.time()\n",
    "        self.asr_handle.run(wavData)\n",
    "        text = self.asr_handle.output\n",
    "        print(\"ASR预测消耗时间：%dms, 识别结果: %s\" % (round((time.time() - start) * 1000), text))\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebd1b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2.62G/2.62G [12:59<00:00, 3.36MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2.95G/2.95G [04:41<00:00, 10.5MB/s]\n",
      "[2023-10-09 13:25:16,197] [    INFO] - Initialize ASR server engine successfully on device: gpu:0.\n"
     ]
    }
   ],
   "source": [
    "asr = crASR()\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone(device_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a725de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Headset Microphone (Oculus Virt',\n",
       " 'Microphone (WEB CAM)',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " '扬声器 (Realtek High Definition Au',\n",
       " 'Realtek Digital Output (Realtek',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition ',\n",
       " '鑰虫満 (Oculus Virtual Audio Device',\n",
       " '主声音捕获驱动程序',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Headset Microphone (Oculus Virtual Audio Device)',\n",
       " 'Microphone (WEB CAM)',\n",
       " '主声音驱动程序',\n",
       " '扬声器 (Realtek High Definition Audio)',\n",
       " 'Realtek Digital Output (Realtek High Definition Audio)',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (Oculus Virtual Audio Device)',\n",
       " 'Realtek Digital Output (Realtek High Definition Audio)',\n",
       " '扬声器 (Realtek High Definition Audio)',\n",
       " '扬声器 (Dubbing Virtual Device)',\n",
       " 'R240HY (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (Oculus Virtual Audio Device)',\n",
       " '麦克风 (Dubbing Virtual Device)',\n",
       " 'Microphone (JOUNIVO JV601)',\n",
       " 'Headset Microphone (Oculus Virtual Audio Device)',\n",
       " 'Microphone (WEB CAM)',\n",
       " '鑰虫満 ()',\n",
       " 'Output 1 (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Output 2 (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Input (OCULUSVAD Wave Speaker Headphone)',\n",
       " 'Headset Microphone (OCULUSVAD Wave Microphone Headphone)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " '麦克风 (Realtek HD Audio Mic input)',\n",
       " 'SPDIF Out (Realtek HDA SPDIF Out)',\n",
       " '立体声混音 (Realtek HD Audio Stereo input)',\n",
       " '绾胯矾杈撳叆 (Realtek HD Audio Line input)',\n",
       " '麦克风 ()',\n",
       " 'Speakers ()',\n",
       " 'Output (NVIDIA High Definition Audio)',\n",
       " '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))',\n",
       " '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))',\n",
       " '麦克风 (WEB CAM)',\n",
       " '麦克风 (JOUNIVO JV601)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e677c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone = mic_thread(\"local mic\",mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a8bcd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talk..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-09 13:27:18,491] [    INFO] - name 'Scorer' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-09 13:27:18.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpaddlespeech.s2t.modules.ctc\u001b[0m:\u001b[36m_init_ext_scorer\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mbegin to initialize the external scorer for decoding\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\server\\engine\\asr\\python\\asr_engine.py:120\u001b[0m, in \u001b[0;36mPaddleASRConnectionHandler.run\u001b[1;34m(self, audio_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masr_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m infer_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\paddle\\fluid\\dygraph\\base.py:347\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>._decorate_function\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\cli\\asr\\infer.py:300\u001b[0m, in \u001b[0;36mASRExecutor.infer\u001b[1;34m(self, model_type)\u001b[0m\n\u001b[0;32m    299\u001b[0m decode_batch_size \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoding_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff_top_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc_bsearch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m result_transcripts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecode(audio, audio_len)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\s2t\\modules\\ctc.py:285\u001b[0m, in \u001b[0;36mCTCDecoder.init_decoder\u001b[1;34m(self, batch_size, vocab_list, decoding_method, lang_model_path, beam_alpha, beam_beta, beam_size, cutoff_prob, cutoff_top_n, num_processes)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoding_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctc_beam_search\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_ext_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvocab_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_search_decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\s2t\\modules\\ctc.py:192\u001b[0m, in \u001b[0;36mCTCDecoder._init_ext_scorer\u001b[1;34m(self, beam_alpha, beam_beta, language_model_path, vocab_list)\u001b[0m\n\u001b[0;32m    190\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin to initialize the external scorer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor decoding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ext_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mScorer\u001b[49m(beam_alpha, beam_beta,\n\u001b[0;32m    193\u001b[0m                           language_model_path, vocab_list)\n\u001b[0;32m    194\u001b[0m lm_char_based \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ext_scorer\u001b[38;5;241m.\u001b[39mis_character_based()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Scorer' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m mic_thread\u001b[38;5;241m.\u001b[39mthread_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 15\u001b[0m replyTxt \u001b[38;5;241m=\u001b[39m \u001b[43masr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# send to LLM afterward\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 音纹识别\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m, in \u001b[0;36mcrASR.predict\u001b[1;34m(self, wavData)\u001b[0m\n\u001b[0;32m     34\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masr_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masr_handle\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\paddlespeech\\server\\engine\\asr\\python\\asr_engine.py:131\u001b[0m, in \u001b[0;36mPaddleASRConnectionHandler.run\u001b[1;34m(self, audio_data)\u001b[0m\n\u001b[0;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(e)\n\u001b[1;32m--> 131\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: -1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\paddle\\lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done lisening\n",
      "Listening..\n",
      "Listening..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Listening..\n",
      "Listening..\n",
      "Listening..\n",
      "Listening..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n",
      "Listening..\n",
      "Done lisening\n"
     ]
    }
   ],
   "source": [
    "\n",
    "microphone.start()\n",
    "\n",
    "flag = True\n",
    "while flag:\n",
    "    if mic_thread.mic_queue.empty():\n",
    "        time.sleep(0.1)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    mic_thread.thread_lock.acquire()\n",
    "    msg = mic_thread.mic_queue.get(0)\n",
    "    mic_thread.thread_lock.release()\n",
    "\n",
    "        \n",
    "    replyTxt = asr.predict(msg)\n",
    "        \n",
    "    # send to LLM afterward\n",
    "    # 音纹识别\n",
    "        \n",
    "        \n",
    "    print(replyTxt)\n",
    "        \n",
    "    if (replyTxt == \"停下\"):\n",
    "        flag = False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43337f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe20a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59dfec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_thread.mic_queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "978ae110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<mic_thread(local mic, stopped 7024)>, <mic_thread(local mic, stopped 12264)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_thread.threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe742e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04000e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd154507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516a960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889a42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e1905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talk..\n"
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source) # This filters noise\n",
    "    r.pause_threshold = 1\n",
    "    print(\"Start talk..\")\n",
    "    while True:\n",
    "        print(\"Listening..\")\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8356495",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data = audio.get_wav_data(convert_rate = 16000)\n",
    "io_wav = io.BytesIO(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ec033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3cde665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virt', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Au', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition ', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': '主声音捕获驱动程序', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 13, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 14, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virtual Audio Device)', 'hostApi': 1, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 15, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 1, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 16, 'structVersion': 2, 'name': '主声音驱动程序', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 17, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 18, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 19, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 20, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 21, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 22, 'structVersion': 2, 'name': 'Realtek Digital Output (Realtek High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 23, 'structVersion': 2, 'name': '扬声器 (Realtek High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 24, 'structVersion': 2, 'name': '扬声器 (Dubbing Virtual Device)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.001, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 25, 'structVersion': 2, 'name': '鑰虫満 (Oculus Virtual Audio Device)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 26, 'structVersion': 2, 'name': 'R240HY (NVIDIA High Definition Audio)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 27, 'structVersion': 2, 'name': '麦克风 (Dubbing Virtual Device)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.001, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 28, 'structVersion': 2, 'name': 'Headset Microphone (Oculus Virtual Audio Device)', 'hostApi': 2, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 29, 'structVersion': 2, 'name': 'Microphone (JOUNIVO JV601)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 30, 'structVersion': 2, 'name': 'Microphone (WEB CAM)', 'hostApi': 2, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.003, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 16000.0}\n",
      "{'index': 31, 'structVersion': 2, 'name': '鑰虫満 ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n",
      "{'index': 32, 'structVersion': 2, 'name': 'Output 1 (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 33, 'structVersion': 2, 'name': 'Output 2 (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 34, 'structVersion': 2, 'name': 'Input (OCULUSVAD Wave Speaker Headphone)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 35, 'structVersion': 2, 'name': 'Headset Microphone (OCULUSVAD Wave Microphone Headphone)', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 36, 'structVersion': 2, 'name': 'Speakers (Realtek HD Audio output)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 37, 'structVersion': 2, 'name': '麦克风 (Realtek HD Audio Mic input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 38, 'structVersion': 2, 'name': 'SPDIF Out (Realtek HDA SPDIF Out)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 39, 'structVersion': 2, 'name': '立体声混音 (Realtek HD Audio Stereo input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 40, 'structVersion': 2, 'name': '绾胯矾杈撳叆 (Realtek HD Audio Line input)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 41, 'structVersion': 2, 'name': '麦克风 ()', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 42, 'structVersion': 2, 'name': 'Speakers ()', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 43, 'structVersion': 2, 'name': 'Output (NVIDIA High Definition Audio)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 44, 'structVersion': 2, 'name': '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 1, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n",
      "{'index': 45, 'structVersion': 2, 'name': '鑰虫満 (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(WH-1000XM3))', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n",
      "{'index': 46, 'structVersion': 2, 'name': '麦克风 (WEB CAM)', 'hostApi': 3, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 16000.0}\n",
      "{'index': 47, 'structVersion': 2, 'name': '麦克风 (JOUNIVO JV601)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# 查找虚拟麦克风的设备索引\n",
    "# 使用VB-Audio Virtual Cable\n",
    "\n",
    "mic_index = None\n",
    "for i in range(audio.get_device_count()):\n",
    "    print(audio.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa98fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b45ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e686475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9034b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"audio_file.wav\", \"wb\") as file:\n",
    "    file.write(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b87fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2adc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-30 10:39:44,235] [   ERROR] - Set device failed, please check if device is already used and the parameter 'device' in the yaml file\n",
      "[2023-09-30 10:39:44,236] [   ERROR] - 'dict' object has no attribute 'device'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr = ASREngine()\n",
    "asr.init({'model':'conformer_wenetspeech',\n",
    "            'lang':'zh',\n",
    "            'sample_rate':16000,\n",
    "            'cfg_path':None,  # 自定义配置文件路径(可选)\n",
    "            'ckpt_path':None,  # 自定义模型文件路径(可选)\n",
    "            'decode_method':'attention_rescoring',\n",
    "            'force_yes':True,\n",
    "            'device':'cuda'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
