torchrun --nproc_per_node 2 talk-7b.py --ckpt_dir llama-2-13b-chat --tokenizer_path tokenizer.model --max_seq_len 256 --max_batch_size 2


torchrun --nproc_per_node 1 talk-7b.py --ckpt_dir llama-2-7b-chat --tokenizer_path tokenizer.model --max_seq_len 256 --max_batch_size 2