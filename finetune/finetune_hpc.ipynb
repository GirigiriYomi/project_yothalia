{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126caef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.conda_env\\yothalia\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin D:\\.conda_env\\yothalia\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd190d",
   "metadata": {},
   "source": [
    "## Install Model and Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ea292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf8_config = BitsAndBytesConfig(\n",
    "   load_in_8bit=True,\n",
    "   bnb_8bit_quant_type=\"nf8\",\n",
    "   bnb_8bit_use_double_quant=True,\n",
    "   bnb_8bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.02,\n",
    "        target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\",\"lm_head\"],\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51fee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"internlm/internlm-chat-7b\", \n",
    "                                          \n",
    "                                          trust_remote_code=True,\n",
    "                                          cache_dir='../yothalia/server/model_weights/internlm/internlm-chat-7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf64c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"internlm/internlm-chat-7b\", \n",
    "                                          \n",
    "                                          trust_remote_code=True,\n",
    "                                          cache_dir='../yothalia/server/model_weights/internlm/internlm-chat-7b')\n",
    "# Set `torch_dtype=torch.float16` to load model in float16, otherwise it will be loaded as float32 and cause OOM Error.\n",
    "model = AutoModelForCausalLM.from_pretrained(\"internlm/internlm-chat-7b\",\n",
    "                                             quantization_config=nf8_config,\n",
    "                                             torch_dtype=torch.float16, \n",
    "                                             trust_remote_code=True,\n",
    "                                             cache_dir='../yothalia/server/model_weights/internlm/internlm-chat-7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': \n",
    "                       ['<<SYS>>','<</SYS>>','[INST]','[/INST]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune')\n",
    "\n",
    "# Optionally, save the model as well\n",
    "model.save_pretrained('../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51641cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d0024",
   "metadata": {},
   "source": [
    "## Load Model and Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d2ba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:44<00:00, 22.14s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune\", \n",
    "                                                load_in_4bit= True,\n",
    "                                                #peft_config=config,\n",
    "                                                trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43b85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune\",\n",
    "                                            trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13514d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"../yothalia/server/model_weights/internlm/internlm-chat-7b-finetune-lora\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "#model.add_adapter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b76a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acafbea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,693,248 || all params: 7,363,674,176 || trainable%: 0.5662016950164418\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03d72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5edaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3527ddb1",
   "metadata": {},
   "source": [
    "## Set Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e156b",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09cd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "132520a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train_sample/csv/train.csv',index_col=0).reset_index(drop=True)\n",
    "# shuffle data\n",
    "#df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbdef8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(lambda x: tokenizer(x, padding='max_length', truncation=True, max_length=512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d98d8e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20020</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20021</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20022 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             train\n",
       "0      [input_ids, attention_mask]\n",
       "1      [input_ids, attention_mask]\n",
       "2      [input_ids, attention_mask]\n",
       "3      [input_ids, attention_mask]\n",
       "4      [input_ids, attention_mask]\n",
       "...                            ...\n",
       "20017  [input_ids, attention_mask]\n",
       "20018  [input_ids, attention_mask]\n",
       "20019  [input_ids, attention_mask]\n",
       "20020  [input_ids, attention_mask]\n",
       "20021  [input_ids, attention_mask]\n",
       "\n",
       "[20022 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfa8c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[-200:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cb06ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11afe179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19819</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19821</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19822 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             train\n",
       "0      [input_ids, attention_mask]\n",
       "1      [input_ids, attention_mask]\n",
       "2      [input_ids, attention_mask]\n",
       "3      [input_ids, attention_mask]\n",
       "4      [input_ids, attention_mask]\n",
       "...                            ...\n",
       "19817  [input_ids, attention_mask]\n",
       "19818  [input_ids, attention_mask]\n",
       "19819  [input_ids, attention_mask]\n",
       "19820  [input_ids, attention_mask]\n",
       "19821  [input_ids, attention_mask]\n",
       "\n",
       "[19822 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9bbdfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=3,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  #max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=4,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir='./ckp',\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=1, # Number of update steps between two evaluations\n",
    "  save_steps=1, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=4, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adamw_torch\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=4,\n",
    "  greater_is_better=False,\n",
    "    \n",
    "  # Parallel Training Param\n",
    "\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf79f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Status: ParallelMode.NOT_PARALLEL\n"
     ]
    }
   ],
   "source": [
    "print('Parallel Status:',training_args.parallel_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf1ba512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=df[0:100],\n",
    "    eval_dataset=df[101:121],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7161ee55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "88",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 88",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\transformers\\trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1554\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\transformers\\trainer.py:1816\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1815\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1816\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1817\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\accelerate\\data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\.conda_env\\yothalia\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 88"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4af29f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [input_ids, attention_mask]\n",
       "1     [input_ids, attention_mask]\n",
       "2     [input_ids, attention_mask]\n",
       "3     [input_ids, attention_mask]\n",
       "4     [input_ids, attention_mask]\n",
       "5     [input_ids, attention_mask]\n",
       "6     [input_ids, attention_mask]\n",
       "7     [input_ids, attention_mask]\n",
       "8     [input_ids, attention_mask]\n",
       "9     [input_ids, attention_mask]\n",
       "10    [input_ids, attention_mask]\n",
       "11    [input_ids, attention_mask]\n",
       "12    [input_ids, attention_mask]\n",
       "13    [input_ids, attention_mask]\n",
       "14    [input_ids, attention_mask]\n",
       "15    [input_ids, attention_mask]\n",
       "16    [input_ids, attention_mask]\n",
       "17    [input_ids, attention_mask]\n",
       "18    [input_ids, attention_mask]\n",
       "19    [input_ids, attention_mask]\n",
       "Name: train, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"train\"][100:120].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408598ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57780c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yothalia",
   "language": "python",
   "name": "yothalia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
